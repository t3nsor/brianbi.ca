<h2>Section 7.6. Normalizers</h2>
<p><span class="problem">Exercise 7.6.1</span> They are conjugate by the unit
antidiagonal matrix \(J_n\), for example, for \(n = 3\),
\[
J_3 = \begin{pmatrix} 0 &amp; 0 &amp; 1 \\
0 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 0 \end{pmatrix}
\]
Verification is left as an exercise.</p>

<p><span class="problem">Exercise 7.6.2</span> Fix \(n\); we will assume all
matrices are \(n \times n\) in what follows. We will use the fact the group
\(U\) of upper triangular matrices with all diagonal entries equal to one is
generated by the elementary matrices of the first type (1.2.3) that are
upper triangular. Let \(E(i, j, c)\) be the elementary matrix of the first kind
where \(E_{ij} = c\) and \(j &gt; i\). Let \(A\) be some other matrix. Then
\(E(i, j, c)A\) is \(A\) with \(c\) times the \(j\)<sup>th</sup> row added to
the \(i\)<sup>th</sup> row, while \(AE(i, j, c)\) is \(A\) with \(c\) times the
\(i\)<sup>th</sup> column added to the \(j\)<sup>th</sup> column. Therefore, in
general, left-multiplication by an element of \(U\) is equivalent to
some sequence of elementary row operations of the first kind that propagate
<q>upward</q> and <i>vice versa</i> while right-multiplication by an element of
\(U\) is equivalent to some sequence of elementary column operations of the
first kind that propagate <q>rightward</q> and <i>vice versa</i>. This gives us
the intuition necessary to solve the problem.</p>

<p>Suppose \(A\) is invertible but not upper triangular. Let \(r\) be the
bottommost row of \(A\) that contains a nonzero entry to the left of the
diagonal, call it \(A_{rc}\) (where \(r &gt; c\)). Then \(A E(c, r, 1)\)
differs from \(A\) at the diagonal entry \((r, r)\). There is no sequence
of upward elementary row operations of the first kind that can reproduce
\(A E(c, r, 1)\) starting from \(A\), since by the assumption of the maximality
of \(r\), all entries below \(A_{rr}\) vanish (and thus, such operations can't
modify \(A_{rr}\)). Therefore the equation \(A E(c, r, 1) = MA\) has no
solution with \(M \in U\). This establishes \(A E(c, r, 1) A^{-1} \notin U\).
Therefore \(A \notin N(U)\). Since this was true for all \(A \in
GL_n(\mathbb{C}) \setminus B\), we conclude \(N(U) \subseteq B\).</p>

<p>To see that \(N(B) \subseteq B\) the idea is very similar&mdash;we just need
to add the fact that \(B\) is generated by the upper triangular elementary
matrices of the first type together with the elementary matrices of the third
type. Given \(A \in GL_n(\mathbb{C}) \setminus B\), choose \(r, c\) as above
and note that \(A E(c, r, 1) = MA\) has no solution with \(M \in B\) either
since the only allowed type of row operation that can modify either \(A_{rc}\)
or \(A_{rr}\) is scaling of row \(r\), but this will never have the same
effect as adding \(A_{rc}\) to \(A_{rr}\) given that the former is nonzero.</p>

<p>It is evident that \(B \subseteq N(B)\), therefore \(N(B) = B\). Also, the
product of two upper triangular matrices has diagonal entries given by the
products of corresponding diagonal entries in the two factors, so the
conjugation of a matrix in \(U\) by one in \(B\) not only lies in \(B\) but
also lies in \(U\) as well. Therefore \(B \subseteq N(U)\) as well, which
establishes \(N(U) = B\).</p>
<div class="qed"></div>

<p><span class="problem">Exercise 7.6.3</span> As in Exercise 7.6.2, we work
with fixed \(n\). Suppose \(A \in GL_n(\mathbb{R})\). If \(\sigma \in P\),
then \(\sigma A\) is \(A\) with its row set permuted, and \(A \sigma\) is \(A\)
with its column set permuted. If \(A \in N(P)\), then this is equivalent to
saying that for all permutations \(\sigma \in P\), we can find \(\tau \in P\)
with \(A\sigma = \tau A\). That is, every matrix obtained by permuting \(A\)'s
column set is also obtainable by permuting \(A\)'s row set.
Our task is simply to find all invertible matrices
with this property.</p>

<p>First, note that if \(A\) has this property then each of its rows must
itself have no more than \(n\) distinct permutations of its entries. If some
row's entries can be permuted in more than \(n\) ways, at least one of those
must be unequal to an existing row of \(A\). But that permutation of the row's
entries can be formed by permuting the columns of \(A\) and, by assumption, not
by permuting the rows of \(A\). Such \(A\) therefore lie outside \(N(P)\).</p>

<p>The only way that a row can have \(\le n\) distinct permutations of its own
elements is if it contains at most two distinct values among its elements, and
if it does contain two distinct values, one of those appears exactly once.
(For example, there are more than four permutations of \([1, 2, 3, 3]\) and
more than four permutations of \([1, 1, 2, 2]\), but only four permutations of
\([1, 2, 2, 2]\).)</p>

<p>If \(A \in N(P)\) does have some row that contains two distinct values,
then there are \(n\) permutations of this row's elements, and each of them can
be accomplished by permuting \(A\)'s set of columns, so each must also already
occur among the set of \(A\)'s rows. So either all rows of \(A\) consist of
the same two values, the same one of which appears exactly once in each row,
or all rows of \(A\) contain only one distinct value. The latter would imply
that all columns of \(A\) are identical (so \(A\) is singular) so we do not
consider it further.</p>

<p>At this point we know that every \(A \in N(P)\) contains the same value
\(a \in \mathbb{R}\) once and the same value \(b \in \mathbb{R}\) \(n-1\)
times. It is also clear that the entry \(a\) must occur in a different position
in each row, so that all \(n\) possible permutations of each row can occur
among \(A\)'s column set. An example is:
\[
A = \begin{pmatrix} 1 &amp; 2 &amp; 1 \\ 1 &amp; 1 &amp; 2 \\ 2 &amp; 1 &amp; 1
\end{pmatrix}
\]
Such matrices <em>do</em> have the property that every matrix obtained by
permuting their column set is also obtainable by permuting their row set, and
are invertible provided \(a \neq b\). Another way of writing this is
\[
N(P) = \{\alpha J + \beta \sigma \mid \sigma \in P, \alpha \in \mathbb{R},
\beta \in \mathbb{R} \setminus \{0\}\}
\]
where \(J\) denotes the all-ones matrix.</p>

<p><span class="problem">Exercise 7.6.4</span> The subgroup \(H\) must be
cyclic since it is of prime order: \(H = \{1, x, x^2, \ldots, x^{p-1}\}\).
Thus, for every \(g \in G\), either \(gxg^{-1} = x\) or \(gxg^{-1} = x^k\)
where \(k \in \{2, 3, \ldots, p-1\}\). Suppose the latter is true. Then
\(k\) generates a subgroup of \((\mathbb{Z}/p\mathbb{Z})^\times\), of order
greater than 1 but less than \(p\). \(k\) therefore has some prime divisor
\(q &lt; p\). Let \(o\) be the order of \(g\). Then \(x = g^o x g^{-o} =
x^{k^o}\), where \(k^o\) is taken in \((\mathbb{Z}/p\mathbb{Z})^\times\). But
\(o\) is known to be a product of primes greater than or equal to \(p\), so it
cannot be divisible by the order of \(k\), which has a prime divisor \(q\)
less than \(p\). So \(k^o \neq 1\), that is, \(g^o x g^{-o} \neq x\). A
contradiction has been reached. So it must in fact be the case that \(gxg^{-1}
= x\) for all \(x\). If all of \(G\) commutes with \(x\), then all of \(G\)
commutes with \(H = \langle x \rangle\) as well. That is, \(H \in Z(G)\).</p>

<p><span class="problem">Exercise 7.6.5</span> <em>(This solution is due to
Andrej VukoviÄ‡.)</em> The proof of the first part is by induction. For
the base case, let \(|G| = p^2\). Then \(|H| = p\). By Proposition 7.3.3,
\(G\) is abelian, therefore \(N(H) = G\). For the inductive case, suppose the
claim holds for \(|G| = p^2, p^3, \ldots, p^{n-1}\) and suppose \(|G| = p^n\),
and suppose \(N(H) = H\). Now \(Z(G) \subseteq N(H)\), so \(Z(G) \subseteq H\).
By Proposition 7.3.1, \(Z(G)\) is not trivial. Also, \(Z(G)\) can't be all of
\(H\) because in that case \(N(H)\) would be all of \(G\). Let \(G' = G/Z(G)\)
and \(H' = H/Z(G)\). Then \(G'\) is a \(p\)-group of order less than \(p^n\),
\(H'\) is a nontrivial \(p\)-group, and \(H'\) is smaller than \(G'\).  Every
coset of \(Z(G)\) in \(H\) is also a coset of \(Z(G)\) in \(G\), so \(H'\) is a
proper subgroup of \(G'\).</p>

<p>Suppose \(g' \in G' \setminus H'\). Then \(g'\) is the coset \([gZ(G)]\)
where \(g \in G \setminus H\). By assumption that \(N(H) = H\), there exists
some \(h \in H\) such that \(ghg^{-1} \notin H\). Let \(h' = [hZ(G)]\). Then
\(ghg^{-1}\) is a member of the coset \([gZ(G)][hZ(G)][gZ(G)]^{-1} =
g'h'g'^{-1}\). This implies that this coset is not any of the cosets of
\(Z(G)\) in \(H\). Since this construction works for all \(g' \in G' \setminus
H'\), it establishes that the normalizer of \(H'\) in \(G'\) is \(H'\). This
contradicts the induction hypothesis, so our assumption that \(N(H) = H\) must
have been faulty.</p>
<div class="qed"></div>

<p>For the second part, suppose \(H\) is a proper subgroup of \(G\) with index
greater than \(p\). Then there are two operations we can do in order to extend
\(H\) to a larger proper subgroup of \(G\):</p>
<ul>
<li>If \(H\) isn't normal, then \(N(H)\) is smaller than \(G\), and by the
first part, \(N(H)\) is also larger than \(H\). So \(N(H)\) is a larger proper
subgroup of \(G\).</li>
<li>If \(H\) is normal, let \(g \in G \setminus H\) and let \(k\) be the
smallest positive integer such that \(g^{p^k} \in H\). Let \(g' =
g^{p^{k-1}}\), so that \(g' \notin H\) but \(g'^p \in H\). Let \(K = \langle
g' \rangle\) and \(K' = \{1, g', \ldots, g'^{p-1}\}\). (Note that \(K'\) is not
necessarily a subgroup of \(G\).) We claim that \(HK = HK'\). (To see this, let
\(h \in H, k = g'^e\); then use the division algorithm to write \(e = qp + r\)
where \(0 \le r \le p - 1\), so \(hk = (hg'^{qp}) g'^r\) where \(hg'^{qp} \in
H, g'^r \in K'\).) Now Proposition 2.11.4(c) tells us that \(HK\) is a subgroup
of \(G\). Clearly this subgroup is strictly larger than \(H\). But \(HK = HK'\)
and \(|HK'| \le |H||K'| = p|H| &lt; |G|\). So in fact this subgroup \(HK\) is
a larger proper subgroup of \(G\).</li>
</ul>
<p>We can always keep extending \(H\) using one of these two operations until
we obtain a subgroup \(H' \supseteq H\) with index \(p\) in \(G\). By the first
part, \(N(H')\) is strictly larger than \(H'\), so it can only be \(G\) itself.
That is, \(H'\) is normal.</p>
<div class="qed"></div>

<p><span class="problem">Exercise 7.6.6</span> <em>(This solution is due to
Tom Guo. Yes, I should have been able to come up with this myself, but I got
stuck somehow &gt;&lt;)</em>
The number of conjugate subgroups of \(H\) in \(G\) is \([G : N(H)] =
|G|/|N(H)|\). But \(|N(H)| \geq |H|\), so the number of conjugate subgroups is
at most \(|G|/|H|\). However, all conjugate subgroups share the identity
element, so the size of the union of these subgroups is at most \(1 +
(|H| - 1)|G|/|H| = |G| + 1 - |G|/|H|\). Since \(|H|\) is a proper subgroup,
this value is less than \(|G|\), so this proves part (a). Part (b) is obviously
equivalent to part (a).</p>
