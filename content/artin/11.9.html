<h2>Section 11.9. Algebraic Geometry</h2>
<p><span class="problem">Exercise 11.9.1</span></p>
<ol class="subproblems">
<li>The ideal \((x-1, y-4)\) in \(R\) is the image of the ideal
\((x-1, y-4, y^2 + x^3 - 17)\) under the quotient map. Since
\(x = 1, y = 4\) is a zero of \(y^2 + x^3 - 17\), it follows that
\(y^2 + x^3 - 17 \in (x-1, y-4)\). So \((x-1, y-4, y^2 + x^3 - 17) =
(x-1, y-4)\), which is a maximal ideal in \(\C[x, y]\). So the ideal
\((x-1, y-4)\) is maximal in \(R\) by the Correspondence Theorem.</li>
<li>The ideal \((x+1, y+4)\) in \(R\) is the image of the ideal
\((x+1, y+4, y^2 + x^3 - 17)\) under the quotient map. These three polynomials
have no common zeroes, so this ideal is the unit ideal. Therefore
\((x+1, y+4) = R\), and is not maximal in \(R\).</li>
<li>The ideal \(J = (x^3 - 17, y^2)\) in \(R\) is the image of the ideal
\(J' = (x^3 - 17, y^2, y^2 + x^3 - 17)\) in \(\C[x,y]\) under the quotient map,
but \(J'\) is just
\((x^3 - 17, y^2)\). Now the ideal \((x - a, y - b)\) in \(\C[x, y]\) has the
property that its members have \((a, b)\) as their
sole common zero, but all polynomials in \(J'\) have three
common zeroes, namely \(\{(\omega^k \sqrt[3]{17}, 0) \mid k \in
\{0, 1, 2\}\}\), where \(\omega\) is a
primitive cube root of unity. So \(J'\) is not equal to \((x-a, y-b)\) for any
\(a, b \in C\), therefore \(J'\) isn't maximal in \(\C[x, y]\). By the
Correspondence Theorem, we conclude that \((x^3 - 17, y^2)\) is not a maximal
ideal in \(R\).</li>
</ol>

<p><span class="problem">Exercise 11.9.2</span> Each polynomial in
\(R = \C[x_1, \ldots, x_n]\) can be identified with a continuous function from
\(\C^n\) to \(\C\) in the obvious way, which restricts to a function from
\(V\) to \(\C\). Let \(\varphi\) denote this map from
polynomials to functions \(V \to \C\). Clearly \(\varphi\) is a homomorphism of
rings. If \(f \in I\), then the evaluation of \(f\) yields zero for all points
of \(V\), therefore \(\varphi(f)\) is the zero function. Therefore,
\(I \subseteq \ker \varphi\). By the fundamental homomorphism theorem, there is
a unique homomorphism \(\overline{\varphi}\) from the ring \(R/I\) to the
continuous functions from \(V \to \C\), such that \(\overline{\varphi} \circ
\pi = \varphi\), with \(\pi\) being the canonical projection from \(R\) to
\(R/I\). The map \(\overline{\varphi}\) operates in the obvious way:
\(\overline{\varphi}(\overline{f}) = \varphi(f)\) where \(f\) is some element
of \(R\) such that \(\pi(f) = \overline{f}\).</p>

<p><span class="problem">Exercise 11.9.3</span> This directly follows from the
definition of the Cartesian product.</p>

<p><span class="problem">Exercise 11.9.4</span> Let \(S = \{f_1, \ldots,
f_m\}\) be a set of polynomials whose common zeros form the variety \(U\). Let
\(T = \{g_1, \ldots, g_n\}\) be a set of polynomials whose common zeros form
the variety \(V\).</p>
<p>The common zeros of the union \(S \cup T\) are the
set \(U \cap V\); so \(U \cap V\) is a variety.</p>
<p>Consider the set \(ST =
\{fg \mid (f, g) \in S \times T\}\). Let \(x \in \C^n\). If \(x \in U\), so
that \(f(x) = 0\) for all \(f \in S\), then \(fg = 0\) for all
\((f, g) \in S \times T\), so \(x\) belongs to the variety of common zeroes of
\(ST\). The same holds if \(x \in V\), so that \(g(x) = 0\) for all \(g \in
T\). On the other hand, if \(x \notin U\) and \(x \notin V\), then there is
some \(f \in S\) and some \(g \in T\) such that \(f(x) \ne 0\) and \(g(x) \ne
0\), consequently \(fg\) is an element of \(ST\) for which \(x\) is not a zero,
and \(x\) does not belong to the variety of common zeros of \(ST\). Therefore,
the variety of common zeros of \(ST\) is \(U \cup V\).</p>
<p>Algebraically, when \(U \cap V = \emptyset\) it means that there's no
solution to the set of equations \(f_1(x) = \ldots = f_m(x) = g_1(x) = \ldots
= g_n(x) = 0\). When \(U \cup V = \C^n\), it means every \(x \in \C^n\) is a
common zero of either \(S\) or \(T\).</p>

<p><span class="problem">Exercise 11.9.5</span> Let \(I\) be the ideal
generated by the polynomials \(S = \{f_1, \ldots, f_r\}\) and let \(V\) be the
variety of their common zeros.</p>
<p>Suppose \(x \in \C^n\) has the property that \(f(x) = 0\) for all \(f \in
I\). Then, certainly \(f(x) = 0\) for each \(f \in S\). Therefore
\(x \in V\).</p>
<p>Conversely, suppose \(x \in V\). Then \(f(x) = 0\) for all \(f \in S\),
consequently \(f(x) = 0\) for all \(f \in I\).</p>
<p>We have established that \(V\) consists precisely of those points
\(x \in \C^n\) such that \(f(x) = 0\) for all \(f \in I\). So \(V\) depends on
\(I\) only.</p>

<p><span class="problem">Exercise 11.9.6</span> We will state and prove a
lemma:</p>
<p><em>Lemma:</em> The intersection of two algebraic curves in \(\C^2\) is the
union of an algebraic curve with finitely many points.</p>
<p><em>Proof:</em> If either curve is the entire set \(\C^2\), then this is
obvious. Suppose that this is not the case. Each given algebraic curve is
therefore the locus of zeros of some nonzero polynomial in \(\C[x, t]\). Denote
these two polynomials by \(f, g\).  If \(f, g\) have a nonconstant common
factor \(h\), then write \(f = f'h, g = g'h\). If \(f'\) and \(g'\) still have
a nonconstant common factor, then divide it out likewise, and continue this
process until there is no nonconstant common factor left. (Each division must
lower either the \(x\)-degree or the \(t\)-degree of the two polynomials, so
this process cannot continue indefinitely). In this way, write \(f = f_0 h_0,
g = g_0 h_0\), where \(f_0, g_0, h_0 \in \C[x, t]\) and the two polynomials
\(f_0, g_0\) have no nonconstant common factor. Let \(x, t \in \C^2\). Then
we will have \(f(x, t) = g(x, t) = 0\) if and only if at least one of these
two conditions holds:</p>
<ol>
<li>\(h_0(x, t) = 0\)</li>
<li>\(f_0(x, t) = g_0(x, t) = 0\)</li>
</ol>
<p>Therefore the intersection of the two algebraic curves given, which is the
locus of common zeros of \(f\) and \(g\), is the union of the algebraic curve
on which \(h_0\) vanishes, and the set of common zeros of \(f_0\) and \(g_0\),
which, according to Theorem 11.9.10, is finite.</p>
<div class="qed"></div>
<p>Suppose a variety in \(\C^2\) is the locus of common zeros of the
polynomials \(f_1, \ldots, f_r\). Therefore, it is the intersection of \(r\)
algebraic curves. We can now prove that this set is the union of an algebraic
curve and at most finitely many points by induction on \(r\):</p>
<ul>
<li>Base case: \(r = 1\). The intersection is just the single algebraic curve
itself.</li>
<li>Inductive case: suppose there are \(r\) algebraic curves, \(C_1 \ldots
C_r\). The intersection \(C_1 \cap \ldots \cap C_{r-1}\) is, by the induction
hypothesis, the union
\(C' \cup P'\) where \(C'\) is an algebraic curve and \(P'\) is a finite set of
points. Let \(S = C_1 \cap \ldots \cap C_r\). Then \(S = (C' \cup P') \cap
C_r = (C' \cap C_r) \cup (P' \cap C_r)\). Using the Lemma, write
\(C' \cap C_r = C \cup P\) where \(C\) is an algebraic curve and \(P\) is
finite. Then \(S = C \cup (P \cup (P' \cap C_r))\), where \(C\) is an
algebraic curve and \(P \cup (P' \cap C_r)\) is finite, so we are done.</li>
</ul>
<div class="qed"></div>

<p><span class="problem">Exercise 11.9.7</span></p>
<ol class="subproblems">
<li>Substitute \(y = 1 - x\) into the first equation to obtain
\(1 = (1 - x)^2 - x^3 + x^2 = 1 - 2x + 2x^2 - x^3\), or
\(x^3 - 2x^2 + 2x = 0\), which is easily factored to give the three solutions
\(x = 0, x = 1 + i, x = 1 - i\). This gives three solutions to the original
system for \((x, y)\), namely \((0, 1), (1 + i, -i), (1 - i, i)\).</li>
<li>Subtract the two equations to obtain \(y^2 - xy = 0\). This tells us that
there are two possible classes of solutions: those with \(y = 0\) and those
with \(x = y\). When \(y = 0\), both equations reduce to \(x^2 = 1\), so this
gives us two solutions. When \(x = y\), the two equations reduce to
\(3x^2 = 1\), so this gives us another two solutions. There are a total of
four solutions for \((x, y)\), namely \((1, 0), (-1, 0), (\sqrt{1/3},
\sqrt{1/3}), (-\sqrt{1/3}, -\sqrt{1/3})\).</li>
<li>Substitute \(y = x^{-1}\) into the first equation to obtain \(x^{-2} =
x^3\), or \(1 = x^5\). This yields five possible solutions for \(x\), all of
which are valid for the original system because we multiplied by \(x^2\), which
is not zero. So the five solutions to the original system for \((x, y)\) are
\(\{(\omega^k, \omega^{-k}) \mid k \in \{0, 1, 2, 3, 4\}\}\) where \(\omega\)
is a primitive fifth root of unity.</li>
<li>Substitute \(x = -y^2\) into the second equation to obtain
\(0 = y + (-y^2)^2 + 2(-y^2)y^2 + y^4 = y\). Conclude that there is a single
solution, namely \(x = 0, y = 0\).</li>
</ol>

<p><span class="problem">Exercise 11.9.8</span> A solution can be found
<a href="https://math.stackexchange.com/a/685071">here</a>.</p>

<p><span class="problem">Exercise 11.9.9</span> The constant polynomials are
not considered irreducible, so \(f\) is not constant. Therefore
\(\partial f/\partial x\) or \(\partial f/\partial y\) is nonzero (possibly
both). Applying Theorem 11.9.10 to \(f\) and one of its nonzero partial
derivatives yields the desired result.</p>

<p><span class="problem">Exercise 11.9.10</span> We will prove a slightly
stronger statement, which will be useful for the next problem. Let \(\ell \in
\C[x, y]\) be linear and let \(L\) be the locus of its zeros. If \(\ell\)
doesn't divide \(f\), then we'll show that \(f\) has at most \(d\) zeroes on
\(L\).</p>
<p>Write \(\ell = ax + by + c\), where \(a\) and \(b\) aren't both zero.
Without loss of generality, suppose \(b\) is
nonzero. The complex line \(L\) is then equivalent to the locus of points of
the equation \(y = px + q\) where \(p = -a/b\) and \(q = -c/b\). Let
\(g \in \C[x]\) be the polynomial such that \(g(x) = f(x, px + q)\). Since
\(f\) has degree \(d\), it follows that \(g\) has degree at most \(d\), or is
zero. If \(g = 0\), then this is saying that the substitution \(y = px + q\)
in the ring \(\C[x][y]\) yields the zero element of \(\C[x]\), which implies
that the monic polynomial \(y - (px + q)\) divides \(f\) in \(\C[x, y]\). We
assumed this not to be the case, therefore \(g\) is nonzero and has degree at
most \(d\), so there are at most \(d\) values of \(x\) with \(g(x) = 0\),
giving at most \(d\) solutions \((x, px + q)\) to the set of equations
\(\{ax + by + c = 0, f(x, y) = 0\}\), that is, at most \(d\) zeroes of
\(f\) that lie on \(L\).</p>
<p>When we are told that \(f\) is irreducible, it is clear that either \(f\) is
a nonzero constant multiple of \(\ell\), giving \(C = L\), or else \(f\) is not
divisible by \(\ell\), in which case, as proven above, \(C \cap L\) can contain
at most \(d\) points.</p>

<p><span class="problem">Exercise 11.9.11</span></p>
<ol class="subproblems">
<li><p>Let \(r\) be a third point on \(L\). We can choose constants \(c_1,
c_2\), not both zero, such that \(c_1 f_1(r) + c_2 f_2(r) = 0\), as follows. If
\(f_1(r) = 0\),
then choose \(c_1 = 1, c_2 = 0\). If \(f_2(r) = 0\), then choose \(c_1 = 0,
c_2 = 1\). If \(f_1(r)\) and \(f_2(r)\) are both nonzero, then choose \(c_1 =
f_2(r), c_2 = -f_1(r)\). No matter how we choose \(c_1, c_2\), it is clear that
\(c_1 f_1 + c_2 f_2\) already vanishes on \(p\) and \(q\). So the polynomial
\(g = c_1 f_1 + c_2 f_2\) vanishes at three distinct points on \(L\). Without
loss of generality, suppose the equation of \(L\) is \(y = ax + b\). By
Exercise 11.9.10, since \(g\) has total degree at most 2, and yet has three
distinct zeroes on \(L\), it follows that \(y - ax - b\) divides \(g\); so, in
fact, \(g\) vanishes identically on \(L\).</p>
<p>If \(g\) is quadratic in \(y\), then performing division of \(g\) by
\(y - ax - b\) in the variable \(y\) yields a polynomial \(h\) which is linear
in \(y\) with constant coefficient. Write \(h = h_1 y + h_0(x)\) where
\(h_1\) is a constant and \(h_0\) is a polynomial. So \(g = (h_1 y + h_0(x))
(y - ax - b)\). If \(h_0\) has degree greater than 1, the highest-degree
term in \(h_0(x)y\) can't be cancelled by any other terms in the product,
resulting in a contradiction. Therefore \(h\) has total degree 1. If on the
other hand \(g\) is only linear in \(y\), \(g = g_1(x)y + g_0(x)\) where
\(g_1\) has degree at most 1 and \(g_0\) has degree at most 2, then
division by \(y - ax - b\) must yield \(g_1\). In either case, \(g\) is a
product of linear factors.</p></li>
<li><p>It is obvious that any common zeros of \(f_1\) and \(f_2\) are also
zeros of \(g\). If \(g\) is linear, then, by the conditions of the
problem, it doesn't divide
both of \(f_1\) and \(f_2\). Without loss of generality, suppose \(g\) doesn't
divide \(f_1\); in that case, by Exercise 11.9.10, \(g\) and \(f_1\) have at
most two common
zeroes, therefore \(f_1\) and \(f_2\) have at most two common zeroes.</p>
<p>If on the other hand \(g\) is quadratic, then write \(g = g_1 g_2\), the
product of linear factors, as we argued we could do in part (a). The set of
points \((x, y)\) on which \(f_1(x, y) = f_2(x, y) = g_1(x, y) g_2(x, y) = 0\)
is the
union of the sets of points \(S_1\), on which \(f_1(x, y) = f_2(x, y) =
g_1(x, y) = 0\), and \(S_2\), on which \(f_1(x, y) = f_2(x, y) = g_2(x, y) =
0\). By the argument given in the previous paragraph, each of \(S_1\) and
\(S_2\) has size at most 2, so there are a total of at most 4 common zeros of
\(f_1, f_2, g\), and hence a total of at most 4 common zeros of \(f_1\) and
\(f_2\).</p></li>
</ol>
<p><em>Remark:</em> In the first edition of the text, the exercise simply asked
to show that two quadratic polynomials in two variables with no nonconstant
factor in common have at most four common zeros. The exercise is much easier in
the second edition, since part (a) is a hint to part (b).</p>

<p><span class="problem">Exercise 11.9.12</span> Suppose \(f_2(x, t) = 0\).
Then we can write \(t = 1/x\) and substitute this into the equation
\(f_1(x, t) = 0\) to obtain \(x^{-2} + x^2 - 2 = 0\), which implies
\(x^4 - 2x^2 + 1 = 0\). This factorizes as \((x+1)^2(x-1)^2 = 0\), so the only
possible common zeros of \(f_1\) and \(f_2\) are \(x = 1, t = 1\) and
\(x = -1, t = -1\). By inspection, neither is a zero of \(f_3\), so the three
polynomials together have no common zeros.</p>
<p>The problem also asks us to explicitly write 1 as a linear combination of
\(f_1, f_2, f_3\) with polynomial coefficients. Solutions can be found
<a href="https://math.stackexchange.com/a/685143/24692">here</a> and
<a href="https://math.stackexchange.com/a/1069877/24692">here</a>, although
it's not clear to me how they are derived.</p>

<p><span class="problem">Exercise 11.9.13</span> We are given that
\(x(t)\) and \(y(t)\) are not both constant. Without loss of generality,
suppose \(x(t)\) is not constant. If \(\ker\varphi\) is the zero ideal, it is
principal. We proceed assuming that this is not the case.</p>
<p>Let \(d_0\) be the minimum \(y\)-degree of nonzero elements of
\(\ker\varphi\), and let \(S \subseteq \ker\varphi\) consist of the elements
with \(y\)-degree equal to \(d_0\). The coefficient of the \(y^{d_0}\) term of
each polynomial in \(S\) is a polynomial in \(x\). Choose \(P_0 \in S\) such
that the degree of the coefficient of the \(y^{d_0}\) term is minimal.</p>
<p>Suppose there is some \(\alpha \in \C\) such that \(P_0 = (x-\alpha)Q\) with
\(Q \in \C[x, y]\). Then \(0 = \varphi(P_0) = \varphi(x-\alpha)\varphi(Q)
= (x(t) - \alpha)\varphi(Q)\). Since we assumed that \(x(t)\) is not constant,
and since \(\C[t]\) is an integral domain, it follows that \(\varphi(Q) = 0\).
But \(Q\) has the same \(y\)-degree as \(P_0\) and the \(x\)-degree of its
\(y^{d_0}\) term is smaller by 1, which gives a contradiction. So there is in
fact no such \(\alpha\). (This will allow us to apply Proposition 11.9.9
shortly.)</p>
<p>Suppose \(f \in \C(x)[y]\) so that \(f(x(t), y(t)) = 0\). We can always
multiply \(f\) by some polynomial in \(x\) to clear denominators, giving an
element of \(\C[x][y]\) with the same \(y\)-degree as \(f\). It follows that
if \(f\) is nonzero, then the \(y\)-degree of \(f\) is at least \(d_0\).</p>
<p>Let \(P \in \ker\varphi\) be given. We may divide \(P\) by \(P_0\) in the
variable \(y\) in \(\C(x)[y]\), giving \(P = P_0 Q + R\) where \(Q, R \in
\C(x)[y]\), and either \(R\) is zero or the \(y\)-degree of \(R\) is less than
\(d_0\). Now \(R(x(t), y(t)) = P(x(t), y(t)) - P_0(x(t), y(t))
Q(x(t), y(t)) = 0\), so if \(R\) is nonzero, then by the argument in the
previous paragraph, the \(y\)-degree of \(R\) is at least \(d_0\). This would
be a contradiction. Therefore \(R = 0\), and
\(P_0\) divides \(P\) in \(\C(x)[y]\). By Proposition 11.9.9,
\(P_0\) divides \(P\) in \(\C[x, y]\). As this holds for all choices of \(P\),
we conclude that \(\ker\varphi = (P_0)\).</p>
